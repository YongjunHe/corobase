% -*- tex-main-file:"rcu-cc.tex" -*-

\begin{abstract}

The emergence of systems with large main memories and massively parallel processors has triggered a resurgence of new high-performance transaction processing systems. 
Many of these systems adopt lightweight optimistic concurrency control schemes that are suitable only for a small fraction of transactional workloads.
We examine existing systems and argue that---for better or for worse---it is their system architecture that largely dictates the choice of concurrency control they employ.
Therefore, it is quite difficult, if not impossible, to adopt a different concurrency control scheme without significant changes to the rest of the system. 
The architecture also largely determines how the physical conflicts between concurrent threads are dealt, and how recovery is achieved.

We argue that transaction processing systems should be designed from the ground up with four basic requirements: to not heavily rely on partitioning; to provide flexible and robust concurrency control for the logical interactions between transactions; to address the physical interactions between threads in a scalable way; and to have a clear recovery methodology.  
We report on the design and prototype implementation a system, called ERMIA, from the ground up to support the requirements we lay out, and show how the resulting architecture achieves these goals without unnecessary sacrifices to performance in other areas. 
ERMIA's performance is comparable, if not higher, to the performance of the highest-performing open-source in-memory OLTP system in the workloads for which this system was designed for, and it performs up to an order of magnitude higher in workloads with high contention or large read and write sets.

\end{abstract}
