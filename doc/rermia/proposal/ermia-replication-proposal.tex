\documentclass[10pt]{article}
\usepackage[square,sort,comma,numbers]{natbib}
\def\thepapertitle{Fresh replicas with append-only storage}
\usepackage[
  pageanchor=true,
  plainpages=false,
  pdfpagelabels,
  bookmarks,
  bookmarksnumbered,
  pdfborder=0 0 0,  %removes outlines around hyper links in online display
  colorlinks=true,
  linkcolor=blue,
  citecolor=blue,
  pdfpagelayout=TwoPageRight,
  pdftitle={\thepapertitle},
  pdfauthor={Tianzheng Wang},
  pdfsubject={},
  pdfkeywords={},
]{hyperref}

\title{\bf \thepapertitle}
\date{}
\usepackage[left=0.95in,right=0.95in,bottom=0.6in,top=0.6in]{geometry} 
\begin{document}
\author{Tianzheng Wang~~~~~~Ryan Johnson~~~~~~Ippokratis Pandis$^\dagger$\\{\sf University of Toronto~~~~$^\dagger$Cloudera}\vspace{-3mm}}
\maketitle
\thispagestyle{empty}

% explain motivation - staleness caused by serial/slow log replay
Database systems maintain multiple copies of data on different physical machines for high availability. Found in most commercial and open source products (e.g., DB2 and MySQL), log shipping is a practical and popular approach to replication. The primary server periodically ships log records of completed transactions to one or more backups, which upon receiving the log, will start to replay it---often \textit{serially}---to make tuples available for (usually read-only) requests. Such a \textit{parallel-execution, serial-replay} model can easily lead to stale backups~\cite{KuaFu}. Read requests routed to backups might not get fresh data and are often served at lower-than-serializable consistency levels. The ever-increasing single-node throughput brought by recent massively parallel processors and large main memories further widens this freshness gap between the primary and backups.

% reason - old two-copy architecture + advocate append-only system
\textbf{Append-only storage.} For various reasons, traditional database systems store data in two distinct places: first in the log, then the ``real'' datastore. This out-of-place update paradigm necessitates the need for replaying log records on backups, making stale reads prevalent. We advocate an ``append-only'' database system architecture~\cite{ERMIA}, where the log itself is the database. Data accesses are done through another level of indirection using table-private indirection arrays, whose entries point to the record's location (in the log or cached in memory). Each indirection array is indexed by tuple IDs, which in turn are stored in the index's leaf nodes. Instead of replaying the log, a transaction simply follows the index and indirection array to load tuples from the log (depending on policy and memory space, tuples could be cached in memory). As a result, the freshness gap is reduced to its minimum: backups are ready to serve requests once the log is shipped. New hardware such as Infiniband and NVRAM open up more opportunities for fresh replicas in append-only systems. We next highlight two key enablers that make our approach attractive.

% elaborate how log shipping can be done for an append-only system
% want even more freshness? then when to RDMA log buffer? how much of it each time?
\textbf{Fast network.} New network interconnects, such as Inifiniband, allow remote direct memory access (RDMA) at a bandwidth as high as 12GB/s (4xEDR), much faster than conventional Ethernet; our preliminary experiments show that a state-of-the-art in-memory system on a four-socket Xeon machine can generate several hundreds MB of log records per second. Using RDMA, the host can directly send its log buffer to backups when transactions commit or when hardening the log. Infiniband's low latency (e.g., 0.5$\mu$s with 4xEDR) also allows eagerer log shipping policies: the primary can ship part of the log buffer containing a batch of transactions, further reducing staleness. Fast network also makes it possible for log shipping to even compete with other replication approaches such as those based on deterministic execution and quorum: the round-trip time needed to communicate between nodes is vastly shorter and shipping the log is the only communication needed (no replay). At lower communication cost, attempts to guarantee serializability for requests routed to backup servers would become more achievable.

% even even more freshness? NVRAM can help: removes log hardening cost
\textbf{NVRAM.} The next key barrier to fresh replica is the need to harden the log buffer. In traditional systems this basically means a log flush per (group of) transaction commit. Similar to single-node systems~\cite{NVM-DLog}, we discover that using NVRAM (e.g., memristor or flash-backed DRAM) as log buffers also benefits replicated systems in reducing staleness. Backups will become immediately available once it receives the log buffer. Log de-staging can then happen quietly in background to make sure the NVRAM has enough space for incoming log records. This can be further simplified if the system is equipped with a large amount of NVRAM.

% summary and future work
\textbf{Putting everything together.} Append-only storage gives us the opportunity to simplify replication as the log itself is the database. In particular, log shipping becomes literally what it means: \textit{ship the log}, and no more, without the need to reply log records, making transaction execution deterministic, etc. On the hardware side, fast RDMA and NVRAM are the two key enablers. The former makes transmitting data less painful and is vital to make the ``no replay'' part of our approach practical; the latter further reduces backup staleness by implicitly hardening the log. We hope to start with a simple log shipping setup with ERMIA~\cite{ERMIA}, a recent memory-optimized, append-only database system. We will then further explore the integration of serializable execution and NVRAM, as well as other backends, such as distributed file systems, as secondary storage.
\renewcommand{\refname}{}\vspace{-12mm}
\bibliographystyle{acm-custom}
\setlength{\bibsep}{3pt plus 0ex}
\bibliography{ref.bib}
\end{document}