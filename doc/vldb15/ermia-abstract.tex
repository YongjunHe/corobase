% -*- tex-main-file:"rcu-cc.tex" -*-

\begin{abstract}

Large main memories and massively parallel processors have triggered not only a resurgence of new high-performance transaction processing systems, but also the evolving of heterogeneous read-mostly transactions. However, many of these systems adopt lightweight optimistic concurrency control schemes that are only suitable for short, write-intensive workloads. By analyzing the desired features of main-memory optimized database systems, we argue that it is the system architecture that largely dictates the concurrency control scheme a system can employ, hence the type of workloads that can be gracefully handled.
Therefore, it becomes difficult, if not impossible, to adopt a different concurrency control scheme to robustly handle various workloads without significant changes to the rest of the system. 
%The architecture also largely determines how the physical conflicts between concurrent threads are dealt, and how recovery is achieved.

We believe that transaction processing systems should be designed from the ground up with four basic requirements: to not heavily rely on partitioning; to provide flexible and robust concurrency control for the logical interactions between transactions; to address the physical interactions between threads in a scalable way; and to have a clear recovery methodology.  
We report on the design and implementation a system, called ERMIA, from the ground up to support the requirements we lay out, and show how the resulting architecture achieves these goals without unnecessary sacrifices to performance in other areas. 
%ERMIA's performance is comparable, if not higher, to the performance of the highest-performing open-source in-memory OLTP system in the workloads for which this system was designed for, and it performs up to an order of magnitude higher in workloads with high contention or large read and write sets.

\end{abstract}
